
# Mode and Destination Choice {#chap-modechoice}

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(tidyverse)
library(readxl)

```



## Homework {-#hw-modechoice}

Let's first start with a couple of practice problems before using data to estimate
multinomial logit models.

1. Calculate the Non-motorized Travel Time, Auto Utility, Non-motorized Utility,
Auto Probability, Non-motorized Probability, and the Mode Choice Logsum using
the following information:

<div align="center">$\beta$<sub>1</sub> = -0.025,
$\beta$<sub>2</sub> = -0.06257,
$\alpha$<sub>1</sub> = 1,
$\alpha$<sub>2</sub> = -1.2258


$$Highway Time = \begin{vmatrix}0.77 & 1.55 & 21.60\\
1.55 & 0.77 & 20.51\\22.02 & 20.93 & 1.21
\end{vmatrix}$$

$$ Highway Distance = \begin{vmatrix}0 & 0.72 & 12.87\\
0.72 & 0 & 12.49\\12.82 & 12.44 & 0
\end{vmatrix}$$


2. Calculate the Utility, Probability, Trips, and Destination Choice Logsum. Check your answer to make sure the rowsum of the Trips is equal to the productions for each row. The Mode Choice Logsum found in Question 1 should be used as the impedance. Use the following information:

<div align="center">$\beta$<sub>2</sub> = 1.1657,
$\alpha$<sub>2</sub> = Attractions

| n | Productions |
|:---:|:---:|
| 1 | 0.6 |
| 2 | 1.8 |
| 3 | 1.3 |

| n | Attractions | 
|:---:|:---:|
| 1 | 125 |
| 2 | 180 |
| 3 | 210 |

Now, for this week's assignment, you will use data from the 2000 Bay Area Travel
Survey to estimate multinomial logit models that predict mode choice for work
trips. The data is available on [on Box](https://byu.box.com/shared/static/px4v9aycpy7f399fsng2oz4w74tfwgbh.rds). The data
are listed as `worktrips_logitdata.rds`. We will also need to load the 
`mlogit` library package, which contains the tools necessary to estimate
multinomial logit models.

```{r worktrips}
library(mlogit)
worktrips <- read_rds("data/worktrips_logitdata.rds")
```

Because multinomial logit models are so different from other models, 
the data are stored in a special type of data frame. You can see the first several
rows of this data below; Person 1 in household 2 has five alternatives, and they
chose to drive alone. Person 3 chose to take transit.

```{r logitdata}
head(worktrips[,1:8], n=12)
```

Now that your data is cleaned and formatted, you can estimate multinomial logit
models.  To do this, use the ``mlogit()` function, in a manner sort of like you
would use the `lm()` command. One thing to look out for: the difference between
generic and alternative-specific variables.^[This can be confusing for many
students; just remember that the difference between generic and
alternative-specific is in the coefficients, not the variables.]

  - *Generic Variables*: These are coefficients with a single estimated
	parameter. That is, the $\hat{\beta}$ coefficient for these variables has the
	same value in the utility equation for every alternative. These estimates come
	from variables that vary naturally across the alternatives, like the cost of
	travel.
  - *Alternative-Specific Variables*: This type of coefficient has a unique
	estimate for each alternative. That is, $\hat{\beta}_{DA}$ is different from
	$\hat{\beta}_{Walk}$.  This type of estimate comes from variables that are
	constant across alternatives, like the distance of the trip.
	
To specify the model, we use the following construction.
```{r firstmlogit, eval = FALSE}
fit.mnl <- mlogit ( CHOICE ~ Generic | Alt.Specific, data = logitdata )
```

To examine the model output, the standard `summary()` command will produce a
coefficients table and key test statistics. The the `texreg` package will
produce convenient model comparison tables that can be included in a report or
pasted into Excel for further formatting. For your homework, please include a
model comparison table rather than a print out of each model summary.

Question 1: Calculate the likelihood of a model with no covariates
(equal-shares) and a model with constants only (market shares). Estimate a model
with only the travel time, and calculate the McFadden pseudo-$R^2$ statistic
with respect to the equal shares model and the market shares model. Which
statistic is reported by the `summary()` command? Why is this important?

Question 2: Estimate a model with just the total travel time
(`TVTT`) and the cost of the trip (`COST`). These two parameter estimates will
allow you to calculate the value of time for the sample population as 

$$VOT = \frac{60\hat{\beta}_{TVTT}}{100 \hat{\beta}_{COST}}$$ 

Report the value of time you calculate. Is this reasonable?

Question 3: Estimate a model with the out-of-vehicle travel
time (`OVTT`), and the in-vehicle travel time (`IVTT`). What is the
ratio of these parameters? What does this tell you about how people feel waiting
for the bus?

Question 4: Estimate a model with the residential population density
(`RSPOPDEN`) and the workplace employment density (`WKEMPDEN`), controlling for
the affordability of the trip (`COSTINC`). Does land use at the origin or the
destination of the trip affect the mode choice problem more? Is it different
by mode?

Question 5: Estimate a nested logit model including cost, travel time,
out-of-vehicle travel time, and workplace employment density. Group car
alternatives into one nest, and non-car alternatives into another. Constrain the
nesting parameter to a single value (`un.nest.el = TRUE`). What is the estimated
value of the nesting parameter? What are the implications of this parameter
value for across-nest substitution?

Question 6: Estimate another nested logit model with the same nests, but this
time segment the data on income; include households making less than \$50k/year
in one segment and households making at least \$50k in the other. Add vehicles 
per worker as a covariate (`VEHBYWRK`). Comment on how the two segments respond
to the different covariates. Which matters more to which group?

Question 7. Of the models you estimated, which is the preferred in terms of model
likelihood? What about in terms of behavioral sensitivity?

Hint: A tool to compare models is the `screenreg()` function in `library(texreg)`.

## Lab

In practice, small-sample surveys have a difficult time generating estimates of
choice parameters that are both precise and rational. As a result, it is
common to assert choice coefficients that have worked well in comparable
cities and then calibrate the mode-specific constants and distance decay
parameters to match your targets. In this lab you will calibrate the mode choice
models and the destination choice models for the following trip purposes:

  - Home-based Work
  - Home-based Other
  - Home-based Shopping
  
In the Roanoke mode choice model, HBO and HBShopping get combined for mode choice. 
So you will calibrate three purposes in the destination choice model, but only
two in the mode choice model.

Even though trip distribution comes first in the standard four-step process, we 
end up using the mode choice logsums mode choice to inform destination choice. 
Mathematically they happen simultaneously, but in the model it goes 

```
skims > mode choice logsums > destination choice > mode choice
```

As a result you will need to calibrate the models iteratively: first adjust the 
mode choice constants, then the distance decay parameter, then mode choice,
etc., until you are satisfied that the model meets the targets.

### Mode Choice Calibration

The coefficients are found in the `./Params/mc/MC_Coefficients.csv` file. Record
the coefficients in a table in your lab report accompanying a description of the
purpose of each coefficient and any notable values. These coefficients are
fixed; they should not change as part of this exercise.

```{r coeff.table}
read_csv("data/rvtpo_data/MC_Coefficients.csv") %>%
  pander::pander()
```

The mode-specific constants are in a separate file, `./Params/mc/MC_Constants.csv`.
The reference alternative in the choice model is Drive Alone, and the alternatives
with their nesting structure are:

```
Trips
|-- Auto
|   |--Drive
|   |--Share
|
|-- Transit
|   |--Local
|   |--Premium
|
|-- Non-motorized
```
```{r constants.table}
read_csv("data/rvtpo_data/MC_Constants.csv") %>%
  pander::pander()
```

There is currently no premium service in the model, so changing its constant
will not result in more people taking it. But the structure for it exists, if the
MPO wants to look at some future transit options.

For initial values for the alternative-specific constants, you can use
parameters you estimated in the homework. After you run the destination choice 
model and adjust its calibration (see below), run the mode choice model and look
at the mode choice report. Calculate new alternative specific constants using the
bias adjustment formula,

$$\alpha_{n+1} = \alpha_n + \log(A_j / S_j) $$

Where $A_j$ is the population share (target) and $S_j$ is the model share.
The population shares (targets) are given below.


```{r mc_targets}
# Population shares (targets)
read_xlsx("data/rvtpo_data/mc.xlsx")  %>%
  knitr::kable(digits = 1)
```



### Destination Choice Calibration

A destination choice model has three basic components: 

  - A size term: these are the trip attraction rates
  - An impedance term: this is the mode choice logsum
  - Calibration constants

Return to your trip generation lab where you estimated and adjusted attraction
rates for different land uses. These attraction rates are the size terms of the
destination choice model; replace the dummy rates in the model with your
estimated rates.

The coefficient on the logsum term should match the nesting parameter in the
mode choice model. This link is what allows for a simultaneous mode and
destination choice.

Instead of alternative-specific constants, a destination choice model includes
calibration constants based on distance-decay functions. By adjusting these 
parameters, we can make the modeled trip length frequency distribution match the
observed distribution. The roanoke model has three basic versions that can be combined
(but really don't need to be)

  - A distance polynomial ($\beta_d d + \beta_{d2} d^2 + \beta_{d3} d^3$)
  - A logarithmic decay function ($\beta_d \log(d)$)
  - A set of bins for trips within specific mile ranges, 0-1, 1-2, etc.
  
There is also an intrazonal constant, which we can leave alone for this lab.
Remember that most of the work should be done by the logsum and the size term,
and that the constants shouldn't generally violate basic travel behavior theory.
These constants are really just here to nudge the distribution in one direction
or another.

The table and figure below show the observed trip length frequency distributions
for the purposes you need to calibrate. An Excel file with the values is on 
LearningSuite.

```{r tlfd}
tlfd <- read_xlsx("data/rvtpo_data/tlfd.xlsx")
knitr::kable(tlfd)
```

```{r tfld-plot}
ggplot(tlfd %>% gather(purpose, share, HBW:HBSH), 
       aes(x = LOW, y = share, color = purpose)) +
  geom_line() +
  xlab("Distance") + ylab("%Trips")
```

The modeled TLFD for each purpose can be had on the model home screen as an
output of the trip distribution model. Calculate the error between your observed
and modeled TLFD. Determine which calibration curve you will use (you may decide
to use different curves for different purposes). Find the coefficients of the
curve that will compensate for the error in the model.

Re-run the destination choice model with your new coefficients, run the mode choice
model, and adjust the coefficients over there.


### Report 
Your lab report should describe the trip distribution and mode choice models;
include discussions of the coefficients and your process to calibrate the mode
and distance constants. Provide results of the calibration including observed and 
modeled trip length frequency distributions.
